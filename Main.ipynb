{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.metrics import confusion_matrix, top_k_accuracy_score\n",
    "import torchvision                                                       \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor\n",
    "from numpy import random as rd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "trainData = datasets.FashionMNIST(root=\"./\",\n",
    "                                  train=True,\n",
    "                                  transform=ToTensor(),\n",
    "                                  download=True\n",
    "                                  )\n",
    "trainLoad = DataLoader(trainData, \n",
    "                       batch_size=60, \n",
    "                       shuffle=True, \n",
    "                       drop_last=False\n",
    "                       )\n",
    "# test data\n",
    "testData = datasets.FashionMNIST(root=\"./\",\n",
    "                                  train=False,\n",
    "                                  transform=ToTensor(),\n",
    "                                  download=True\n",
    "                                  )\n",
    "testLoad = DataLoader(testData, \n",
    "                     batch_size=60, \n",
    "                     shuffle=True, \n",
    "                     drop_last=False\n",
    "                     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride = stride, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride = 1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels*2, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels*2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride = stride, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride = 1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride = 1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels*2, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels*2)\n",
    "        )\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        # out = self.conv1(x)\n",
    "        # out = self.conv2(out)\n",
    "        out = torch.cat([self.conv1(x), self.conv2(x)], 1)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renset Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for ResNet model that extend from nn.Module\n",
    "class Resnet(nn.Module):\n",
    "    # initialize the resnet model with inputted block type, list of blockNum \n",
    "    def __init__(self, block, blockList):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(inChannels=1, outChannels=64, kernelSize=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2, 1)\n",
    "        )\n",
    "        \n",
    "        # 3, 3, 3, 3 blocks\n",
    "        self.block0 = self._make_layer(block,   inChannels=64,  inChannels=64, blocksNum=blockList[0], stride=1)\n",
    "        self.block1 = self._make_layer(block,  inChannels=256, inChannels=128, blocksNum=blockList[1], stride=1)\n",
    "        self.block2 = self._make_layer(block,  inChannels=512, inChannels=256, blocksNum=blockList[2], stride=1)\n",
    "        self.block3 = self._make_layer(block, inChannels=1024, inChannels=512, blocksNum=blockList[3], stride=2)\n",
    "\n",
    "        # apply 2D adaptive average pooling from 1 input to 1 plane\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        # flatten the data into 1 dimension\n",
    "        self.flatten = nn.Flatten()\n",
    "        # apply dropout to output with 60% percent chance\n",
    "        self.drop = nn.Dropout(0.6)\n",
    "        # connect 2048 input nodes into 10 output nodes\n",
    "        self.fc = nn.Linear(2048, 10)\n",
    "\n",
    "    # helper function that adds layer by layer along with the res block\n",
    "    def _make_layer(self, block, inChannels, outChannels, blocksNum, stride):\n",
    "        layers = []\n",
    "        layers.append(block(inChannels, outChannels, stride))\n",
    "\n",
    "        inChannels = outChannels * block.expansion\n",
    "        for _ in range(1, blocksNum):\n",
    "            layers.append(block(inChannels, outChannels, 1))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    # forward function \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.block0(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epoch\n",
    "epochNum=20\n",
    "# learning rate\n",
    "learningRate = 0.01\n",
    "# weight decay\n",
    "weightDecayRate = 0.001\n",
    "# momentum\n",
    "momentumAmount = 0.9\n",
    "# setting up the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# setting up the model\n",
    "model = Resnet(ResidualBlock, [3, 4, 6, 3]).to(device)\n",
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learningRate, weight_decay=weightDecayRate, momentum=momentumAmount)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_step = len(trainLoad)\n",
    "\n",
    "# for epoch in range(epochNum):\n",
    "#     for i, (images, labels) in enumerate(trainLoad):\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "        \n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "        \n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         del images, labels, outputs\n",
    "#         torch.cuda.empty_cache()\n",
    "#         gc.collect()\n",
    "        \n",
    "#     print ('Epoch [{}/{}], Loss: {:.4f}' \n",
    "#                    .format(epoch+1, epochNum, loss.item()))\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "#         for images, labels in valid_loader:\n",
    "#             images = images.to(device)\n",
    "#             labels = labels.to(device)\n",
    "#             outputs = model(images)\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#             del images, labels, outputs\n",
    "    \n",
    "#         print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss ,current = loss.item(), batch * len(X)\n",
    "            print(f\"loss:{loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn, Train = False):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    if Train:\n",
    "        print(f\"Train Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    else:\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "def train_loop(model, epochs):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(trainLoad, model, loss_fn, optimizer)\n",
    "        test(trainLoad, model, loss_fn, Train = True)\n",
    "        test(trainLoad, model, loss_fn)\n",
    "    print(\"Done!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myres50 = ResNet(ResidualBlock, [3, 4, 6, 3])\n",
    "train_loop(myres50.cuda(), 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01364b1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.500\n",
      "[1,   200] loss: 0.784\n",
      "[1,   300] loss: 0.664\n",
      "[1,   400] loss: 0.620\n",
      "[1,   500] loss: 0.615\n",
      "[1,   600] loss: 0.563\n",
      "[1,   700] loss: 0.542\n",
      "[1,   800] loss: 0.533\n",
      "[1,   900] loss: 0.493\n",
      "[2,   100] loss: 0.492\n",
      "[2,   200] loss: 0.458\n",
      "[2,   300] loss: 0.450\n",
      "[2,   400] loss: 0.460\n",
      "[2,   500] loss: 0.438\n",
      "[2,   600] loss: 0.418\n",
      "[2,   700] loss: 0.436\n",
      "[2,   800] loss: 0.435\n",
      "[2,   900] loss: 0.419\n",
      "[3,   100] loss: 0.397\n",
      "[3,   200] loss: 0.414\n",
      "[3,   300] loss: 0.377\n",
      "[3,   400] loss: 0.385\n",
      "[3,   500] loss: 0.395\n",
      "[3,   600] loss: 0.397\n",
      "[3,   700] loss: 0.389\n",
      "[3,   800] loss: 0.380\n",
      "[3,   900] loss: 0.383\n",
      "[4,   100] loss: 0.363\n",
      "[4,   200] loss: 0.361\n",
      "[4,   300] loss: 0.369\n",
      "[4,   400] loss: 0.363\n",
      "[4,   500] loss: 0.361\n",
      "[4,   600] loss: 0.353\n",
      "[4,   700] loss: 0.369\n",
      "[4,   800] loss: 0.357\n",
      "[4,   900] loss: 0.349\n",
      "[5,   100] loss: 0.327\n",
      "[5,   200] loss: 0.326\n",
      "[5,   300] loss: 0.335\n",
      "[5,   400] loss: 0.357\n",
      "[5,   500] loss: 0.339\n",
      "[5,   600] loss: 0.342\n",
      "[5,   700] loss: 0.333\n",
      "[5,   800] loss: 0.326\n",
      "[5,   900] loss: 0.345\n",
      "[6,   100] loss: 0.319\n",
      "[6,   200] loss: 0.317\n",
      "[6,   300] loss: 0.335\n",
      "[6,   400] loss: 0.316\n",
      "[6,   500] loss: 0.316\n",
      "[6,   600] loss: 0.321\n",
      "[6,   700] loss: 0.321\n",
      "[6,   800] loss: 0.300\n",
      "[6,   900] loss: 0.308\n",
      "[7,   100] loss: 0.320\n",
      "[7,   200] loss: 0.307\n",
      "[7,   300] loss: 0.318\n",
      "[7,   400] loss: 0.311\n",
      "[7,   500] loss: 0.294\n",
      "[7,   600] loss: 0.290\n",
      "[7,   700] loss: 0.306\n",
      "[7,   800] loss: 0.277\n",
      "[7,   900] loss: 0.305\n",
      "[8,   100] loss: 0.279\n",
      "[8,   200] loss: 0.298\n",
      "[8,   300] loss: 0.293\n",
      "[8,   400] loss: 0.308\n",
      "[8,   500] loss: 0.284\n",
      "[8,   600] loss: 0.288\n",
      "[8,   700] loss: 0.280\n",
      "[8,   800] loss: 0.275\n",
      "[8,   900] loss: 0.285\n",
      "[9,   100] loss: 0.274\n",
      "[9,   200] loss: 0.277\n",
      "[9,   300] loss: 0.285\n",
      "[9,   400] loss: 0.269\n",
      "[9,   500] loss: 0.255\n",
      "[9,   600] loss: 0.278\n",
      "[9,   700] loss: 0.284\n",
      "[9,   800] loss: 0.270\n",
      "[9,   900] loss: 0.276\n",
      "[10,   100] loss: 0.270\n",
      "[10,   200] loss: 0.256\n",
      "[10,   300] loss: 0.259\n",
      "[10,   400] loss: 0.276\n",
      "[10,   500] loss: 0.256\n",
      "[10,   600] loss: 0.263\n",
      "[10,   700] loss: 0.266\n",
      "[10,   800] loss: 0.271\n",
      "[10,   900] loss: 0.255\n",
      "[11,   100] loss: 0.248\n",
      "[11,   200] loss: 0.256\n",
      "[11,   300] loss: 0.250\n",
      "[11,   400] loss: 0.260\n",
      "[11,   500] loss: 0.259\n",
      "[11,   600] loss: 0.262\n",
      "[11,   700] loss: 0.250\n",
      "[11,   800] loss: 0.250\n",
      "[11,   900] loss: 0.246\n",
      "[12,   100] loss: 0.251\n",
      "[12,   200] loss: 0.231\n",
      "[12,   300] loss: 0.253\n",
      "[12,   400] loss: 0.238\n",
      "[12,   500] loss: 0.245\n",
      "[12,   600] loss: 0.263\n",
      "[12,   700] loss: 0.246\n",
      "[12,   800] loss: 0.238\n",
      "[12,   900] loss: 0.240\n",
      "[13,   100] loss: 0.254\n",
      "[13,   200] loss: 0.248\n",
      "[13,   300] loss: 0.222\n",
      "[13,   400] loss: 0.236\n",
      "[13,   500] loss: 0.245\n",
      "[13,   600] loss: 0.227\n",
      "[13,   700] loss: 0.225\n",
      "[13,   800] loss: 0.245\n",
      "[13,   900] loss: 0.241\n",
      "[14,   100] loss: 0.242\n",
      "[14,   200] loss: 0.225\n",
      "[14,   300] loss: 0.230\n",
      "[14,   400] loss: 0.219\n",
      "[14,   500] loss: 0.236\n",
      "[14,   600] loss: 0.226\n",
      "[14,   700] loss: 0.227\n",
      "[14,   800] loss: 0.226\n",
      "[14,   900] loss: 0.226\n",
      "[15,   100] loss: 0.228\n",
      "[15,   200] loss: 0.220\n",
      "[15,   300] loss: 0.223\n",
      "[15,   400] loss: 0.214\n",
      "[15,   500] loss: 0.216\n",
      "[15,   600] loss: 0.222\n",
      "[15,   700] loss: 0.229\n",
      "[15,   800] loss: 0.228\n",
      "[15,   900] loss: 0.221\n",
      "[16,   100] loss: 0.221\n",
      "[16,   200] loss: 0.215\n",
      "[16,   300] loss: 0.214\n",
      "[16,   400] loss: 0.223\n",
      "[16,   500] loss: 0.217\n",
      "[16,   600] loss: 0.212\n",
      "[16,   700] loss: 0.208\n",
      "[16,   800] loss: 0.219\n",
      "[16,   900] loss: 0.222\n",
      "[17,   100] loss: 0.213\n",
      "[17,   200] loss: 0.205\n",
      "[17,   300] loss: 0.207\n",
      "[17,   400] loss: 0.204\n",
      "[17,   500] loss: 0.224\n",
      "[17,   600] loss: 0.211\n",
      "[17,   700] loss: 0.203\n",
      "[17,   800] loss: 0.204\n",
      "[17,   900] loss: 0.213\n",
      "[18,   100] loss: 0.198\n",
      "[18,   200] loss: 0.197\n",
      "[18,   300] loss: 0.203\n",
      "[18,   400] loss: 0.216\n",
      "[18,   500] loss: 0.206\n",
      "[18,   600] loss: 0.198\n",
      "[18,   700] loss: 0.198\n",
      "[18,   800] loss: 0.211\n",
      "[18,   900] loss: 0.205\n",
      "[19,   100] loss: 0.192\n",
      "[19,   200] loss: 0.190\n",
      "[19,   300] loss: 0.199\n",
      "[19,   400] loss: 0.202\n",
      "[19,   500] loss: 0.196\n",
      "[19,   600] loss: 0.193\n",
      "[19,   700] loss: 0.212\n",
      "[19,   800] loss: 0.199\n",
      "[19,   900] loss: 0.206\n",
      "[20,   100] loss: 0.194\n",
      "[20,   200] loss: 0.190\n",
      "[20,   300] loss: 0.183\n",
      "[20,   400] loss: 0.191\n",
      "[20,   500] loss: 0.199\n",
      "[20,   600] loss: 0.187\n",
      "[20,   700] loss: 0.190\n",
      "[20,   800] loss: 0.192\n",
      "[20,   900] loss: 0.188\n",
      "Accuracy of the network on the 10000 test images: 90 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "# the transforms convert the data to PyTorch tensors and normalize the pixel values to the range [-1, 1]\n",
    "\n",
    "# Load Fashion MNIST dataset\n",
    "train_data = datasets.FashionMNIST(root = 'C:\\\\Users\\\\denis\\\\CACI', train=True, download=True, transform=transform)\n",
    "test_data = datasets.FashionMNIST(root = 'C:\\\\Users\\\\denis\\\\CACI', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "# consists of two convolutional layers (conv1 and conv2), \n",
    "# two dropout layers (dropout1 and dropout2), and two fully connected layers (fc1 and fc2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(self.dropout1(x), 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = nn.functional.relu(self.fc1(self.dropout2(x)))\n",
    "        x = self.fc2(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "# forward pass applies convolutional and pooling operations, flattens the input, \n",
    "# and passes it through the fully connected layers\n",
    "\n",
    "\n",
    "# Initialize the network\n",
    "net = Net()\n",
    "\n",
    "# Define the loss function as cross-entropy loss and optimizer as stochastic gradient descent (SGD)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "# Train the network\n",
    "'''In each epoch, iterate over the training data batches, perform forward and backward passes, \n",
    "update the weights using the optimizer, and calculate the running loss. The loss is printed every 100 batches.'''\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "# Test the network\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "# result: [refers to the current epoch of training, refers to the iteration or batch number within the current epoch]\n",
    "# Lower loss values generally indicate better performance, as it means the model's predictions are closer to the true labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b5575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "# from sklearn.metrics import confusion_matrix, top_k_accuracy_score\n",
    "import torchvision                                                       \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor\n",
    "from numpy import random as rd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([30, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "# transform method\n",
    "transform = transforms.Compose([\n",
    "            # transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize((0.5), (0.5)),\n",
    "    ])\n",
    "\n",
    "# train data\n",
    "trainData = datasets.FashionMNIST(root=\"./\",\n",
    "                                  train=True,\n",
    "                                  transform=transform,\n",
    "                                  download=True\n",
    "                                  )\n",
    "trainLoad = DataLoader(trainData, \n",
    "                       batch_size=30, \n",
    "                       shuffle=True, \n",
    "                       drop_last=False\n",
    "                       )\n",
    "# test data\n",
    "testData = datasets.FashionMNIST(root=\"./\",\n",
    "                                  train=False,\n",
    "                                  transform=transform,\n",
    "                                  download=True\n",
    "                                  )\n",
    "testLoad = DataLoader(testData, \n",
    "                     batch_size=30, \n",
    "                     shuffle=True, \n",
    "                     drop_last=False\n",
    "                     )\n",
    "# Checking the dataset\n",
    "for images, labels in trainLoad:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # print(\"-new block-\")\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        \"\"\" The channel mismatch happens here, with this con2d layer\n",
    "            This is the block made when in_channels=64 and out_channels=128\"\"\"\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        )\n",
    "\n",
    "        # downsample for forwarding\n",
    "        # short = []\n",
    "        # if stride != 1 or in_channels != out_channels * self.expansion:\n",
    "        #     short.append(nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, padding=0))\n",
    "        #     short.append(nn.BatchNorm2d(out_channels * self.expansion))\n",
    "        # self.short = nn.Sequential(*short)\n",
    "        # self.relu = nn.ReLU()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels=out_channels\n",
    "        \n",
    "        # print(\"resblock in: \" + str(in_channels))\n",
    "        # print(\"resblock out: \" + str(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # out = torch.cat([self.conv1(residual), self.conv2(residual)], 1)\n",
    "        # residual = self.short(residual)\n",
    "        # out = self.relu(out + residual)\n",
    "        \n",
    "        residual = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        # print(x.size())\n",
    "        \n",
    "        \"\"\" It breaks in making this layer, I think\n",
    "            At this point the tenor going into this is torch.Size([30, 128, 7, 7])\"\"\"\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        if self.downsample != None:\n",
    "            residual = self.downsample(residual)\n",
    "            \n",
    "        x += residual\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renset Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for ResNet model that extend from nn.Module\n",
    "class Resnet(nn.Module):\n",
    "    \n",
    "    # initialize the resnet model with inputted block type, list of blockNum \n",
    "    def __init__(self, block, blockList, input_num, output_num):\n",
    "        super(Resnet, self).__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_num, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # 3, 3, 3, 3 blocks\n",
    "        # self.block0 = self._make_layer(block,   inChannels=64,  outChannels=64, blocksNum=blockList[0], stride=1)\n",
    "        # self.block1 = self._make_layer(block,  inChannels=256, outChannels=128, blocksNum=blockList[1], stride=1)\n",
    "        # self.block2 = self._make_layer(block,  inChannels=512, outChannels=256, blocksNum=blockList[2], stride=1)\n",
    "        # self.block3 = self._make_layer(block, inChannels=1024, outChannels=512, blocksNum=blockList[3], stride=2)\n",
    "        \n",
    "        # print(\"---block0layer---\")\n",
    "        self.block0 = self._make_layer(block,  out_channels=64, blocksNum=blockList[0], stride=1)\n",
    "        # print(\"---block1layer---\")\n",
    "        self.block1 = self._make_layer(block,  out_channels=128, blocksNum=blockList[1], stride=2)\n",
    "        # print(\"---block2layer---\")\n",
    "        self.block2 = self._make_layer(block,  out_channels=256, blocksNum=blockList[2], stride=2)\n",
    "        # print(\"---block3layer---\")\n",
    "        self.block3 = self._make_layer(block,  out_channels=512, blocksNum=blockList[3], stride=2)\n",
    "        \n",
    "        # apply 2D adaptive average pooling from 1 input to 1 plane\n",
    "        # self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.avgpool = nn.AvgPool2d(1, 1)\n",
    "        \n",
    "        # flatten the data into 1 dimension\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # apply dropout to output with 60% percent chance\n",
    "        self.drop = nn.Dropout(0.6)\n",
    "        \n",
    "        # connect 2048 input nodes into 10 output nodes\n",
    "        self.fc = nn.Linear(512*4, output_num)\n",
    "\n",
    "    # helper function that adds layer by layer along with the res block\n",
    "    def _make_layer(self, block: ResidualBlock, out_channels, blocksNum, stride):\n",
    "        downn_sample = None\n",
    "        \n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downn_sample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        # layer that change the number of out channel, in will be inputed out\n",
    "        layers.append(block(self.in_channels, out_channels, stride=stride, downsample=downn_sample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        # print(\"current inplanes: \" + str(self.in_channels))\n",
    "        \n",
    "        # connected large output to smaller out \n",
    "        for _ in range(1, blocksNum):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "            \n",
    "        # print(\"layers made\")\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    # forward function \n",
    "    def forward(self, x: ToTensor):\n",
    "        # initial the first convelution\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        # making block\n",
    "        x = self.block0(x)\n",
    "        # print(\"done block0\")\n",
    "        x = self.block1(x)\n",
    "        # print(\"done block1\")\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        # x = self.drop(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boilerplate(ep, lr, wdr, mom):    \n",
    "    # number of epoch\n",
    "    epochNum=ep\n",
    "    # learning rate\n",
    "    learningRate = lr\n",
    "    # weight decay\n",
    "    weightDecayRate = wdr\n",
    "    # momentum\n",
    "    momentumAmount = mom\n",
    "    # setting up the device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # setting up the model\n",
    "    # block using the ResidualBlock\n",
    "    # blockNums using the inputted list\n",
    "    # input_num of 1 for gray scaled, 3 for color\n",
    "    # output_num of 10 for 10 classes\n",
    "    model = Resnet(ResidualBlock, [3, 4, 6, 3], 1, 10).to(device)\n",
    "    # loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate, weight_decay=weightDecayRate)\n",
    "    total_step = len(trainLoad)\n",
    "    # print(model)\n",
    "    for epoch in range(epochNum):\n",
    "        for i, (images, labels) in enumerate(trainLoad):\n",
    "            # move tensor to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # forward the output and calculate loss\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # backward the output and perform optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # deallocation\n",
    "            del images, labels, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochNum, loss.item()))\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in testLoad:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "        \n",
    "       # print('Accuracy of the network on the {} validation images: {} %'.format(10000, 100 * correct / total))\n",
    "    return correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m20\u001b[39m, \u001b[39m41\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m201\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m         correct, total \u001b[39m=\u001b[39m boilerplate(epoch, \u001b[39m.01\u001b[39;49m, \u001b[39m.001\u001b[39;49m, \u001b[39m.9\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m         rnResults\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(epoch) \u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mBatch: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(batch) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m         rnResults\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39mAccuracy of the network on the \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m validation images: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m10000\u001b[39m, \u001b[39m100\u001b[39m \u001b[39m*\u001b[39m correct \u001b[39m/\u001b[39m total))\n",
      "Cell \u001b[1;32mIn[5], line 36\u001b[0m, in \u001b[0;36mboilerplate\u001b[1;34m(ep, lr, wdr, mom)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m# backward the output and perform optimization\u001b[39;00m\n\u001b[0;32m     35\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 36\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     37\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     39\u001b[0m \u001b[39m# deallocation\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnResults = open('results.txt', 'a')\n",
    "for epoch in range(20, 41):\n",
    "    for batch in range(1, 201):\n",
    "        correct, total = boilerplate(epoch, .01, .001, .9)\n",
    "        rnResults.write(\"Epoch: \" + str(epoch) +\"\\nBatch: \" + str(batch) + \"\\n\")\n",
    "        rnResults.write('Accuracy of the network on the {} validation images: {} %'.format(10000, 100 * correct / total))\n",
    "        rnResults.write(\"\\n\")\n",
    "rnResults.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(dataloader, model, loss_fn, optimizer):\n",
    "#     size = len(dataloader.dataset)\n",
    "#     for batch, (X, y) in enumerate(dataloader):\n",
    "#         X, y = X.cpu(), y.cpu()\n",
    "#         pred = model(X)\n",
    "#         loss = loss_fn(pred, y)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         if batch % 100 == 0:\n",
    "#             loss ,current = loss.item(), batch * len(X)\n",
    "#             print(f\"loss:{loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "# def test(dataloader, model, loss_fn, Train = False):\n",
    "#     size = len(dataloader.dataset)\n",
    "#     num_batches = len(dataloader)\n",
    "#     test_loss, correct = 0, 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for X, y in dataloader:\n",
    "#             X, y = X.cuda(), y.cuda()\n",
    "#             pred = model(X)\n",
    "#             test_loss += loss_fn(pred, y).item()\n",
    "#             correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "#     test_loss /= num_batches\n",
    "#     correct /= size\n",
    "#     if Train:\n",
    "#         print(f\"Train Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "#     else:\n",
    "#         print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "# def train_loop(model, epochs):\n",
    "#     loss_fn = nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
    "#     for t in range(epochs):\n",
    "#         print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "#         train(trainLoad, model, loss_fn, optimizer)\n",
    "#         test(trainLoad, model, loss_fn, Train = True)\n",
    "#         test(trainLoad, model, loss_fn)\n",
    "#     print(\"Done!\")\n",
    "# resnet_model = Resnet(ResidualBlock, [3, 4, 6, 3])\n",
    "# train_loop(resnet_model.cpu(), 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
